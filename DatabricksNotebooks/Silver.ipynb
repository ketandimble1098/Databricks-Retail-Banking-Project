{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "788562a4-71c6-4267-a20c-1fccbdc1953c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Account Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e8a3a4-1dc5-427f-a797-2a6b79299d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e98265ea-b061-47d7-b961-a9a7b19e641f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "Account_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/account/account.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1569d75-2f96-4514-8f74-1c92acc6fd48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Final_Account_df = Account_df.select(\"account_id\", \"district_id\", \"frequency\", col(\"parseddate\").alias(\"issuance_date\"))\n",
    "# display(Final_Account_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99891c92-8059-4a08-938e-324312a0b1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "account_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/account/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56882975-d85d-46cb-8a4a-738622e9d5fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 7"
    }
   },
   "outputs": [],
   "source": [
    "def path_exists(account_path):\n",
    "    try:\n",
    "        dbutils.fs.ls(account_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35408196-0edf-40d5-a7ec-df5489f42459",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 6"
    }
   },
   "outputs": [],
   "source": [
    "# Incremental loading\n",
    "if path_exists(account_path):\n",
    "    silver_df = spark.read.format(\"delta\").load(account_path).select(\"account_id\")\n",
    "    incremental_account_df = Final_Account_df.join(\n",
    "        silver_df,\n",
    "        on=\"account_id\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    incremental_account_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(account_path)\n",
    "else:\n",
    "    Final_Account_df.write.format(\"delta\").mode(\"overwrite\").save(account_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ea3c91-8b8d-4f04-9744-33c05cda4e46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(\"abfss://silver@sabankingkd.dfs.core.windows.net/account/\")\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94d0387-1e5b-4097-b67f-2e1fb8f93397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Card Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "927b3efe-a15e-4113-b3c0-655b037c8c18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Card_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/card/card.csv\")\n",
    "drop_duplicate_card = Card_df.dropDuplicates([\"card_id\"])\n",
    "visa_card = drop_duplicate_card.withColumn(\"type\", when(col(\"type\") == \"VISA Infinite\", \"Infinite\")\n",
    "                                           .when(col(\"type\") == \"VISA Signature\", \"Signature\")\n",
    "                                           .when(col(\"type\") == \"VISA Standard\", \"Standard\")\n",
    "                                           .otherwise(col(\"type\")))\n",
    "Card_final_df = visa_card.select(\"card_id\", \"disp_id\", \"type\", col(\"fulldate\").alias(\"card_date\"))\n",
    "Card_final_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://silver@sabankingkd.dfs.core.windows.net/card/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84289173-6a96-47f1-a687-0b6a2b6109ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(\"abfss://silver@sabankingkd.dfs.core.windows.net/card/\")\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e9c6652-8997-416a-9b13-d4e15092e4e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Client Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57b3cb85-3568-4843-9c24-cc88c4bbc854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/client/client.csv\")\n",
    "client_concat_df = client_df.withColumn(\"fullname\", concat_ws(\" \", col(\"first\"), col(\"middle\"), col(\"last\")))\n",
    "drop_duplicate_card = client_concat_df.dropDuplicates([\"client_id\"])\n",
    "client_final_df = drop_duplicate_card.select(\"client_id\",\"fullname\", \"sex\", col(\"fulldate\").alias(\"birthdate\"), \"age\", \"social\", \"phone\", \"email\", \"address_1\", \"address_2\", \"city\", \"state\", \"zipcode\", \"district_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5021cf17-f49d-4810-a3e7-91575114380f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Incremental load using watermark column\n",
    "client_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/client/\"\n",
    "try:\n",
    "    last_client_id = spark.read.delta(client_path).selectExpr(\"max(client_id)\").cast(\"string\").collect()[0][0] or 0 \n",
    "except:\n",
    "    last_client_id = '0'\n",
    "print(last_client_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "581d2e7e-0d87-420d-9108-69569a70bcd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def path_exists(client_path):\n",
    "    try:\n",
    "        dbutils.fs.ls(client_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46ead1a4-8f56-46b1-8d72-47ba88154f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if path_exists(client_path):\n",
    "    silver_df = spark.read.format(\"delta\").load(client_path).select(\"client_id\")\n",
    "    incremental_client_df = client_final_df.filter(col(\"client_id\") > last_client_id)\n",
    "    incremental_client_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(client_path)\n",
    "else:\n",
    "    client_final_df.write.format(\"delta\").mode(\"overwrite\").save(client_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7524e2f1-4a36-46e4-8287-05f7e7779234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(client_path)\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8028319f-f007-411d-bb00-cb9d86eed963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Position_Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972e3f58-d01f-42d1-8190-1fbf8a24542c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "position_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/position/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5019dd-4978-4704-85ca-aa3be2d382a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "position_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/position/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd458075-3085-4e6d-84f3-2354cc70e643",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def path_exists(position_path):\n",
    "    try:\n",
    "        dbutils.fs.ls(position_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfa07e0-d699-4432-b411-426a399f84b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if path_exists(position_path):\n",
    "    silver_df = spark.read.format(\"delta\").load(position_path).select(\"disp_id\")\n",
    "    incremental_position_df = position_df.join(\n",
    "        silver_df,\n",
    "        on=\"disp_id\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    incremental_position_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(position_path)\n",
    "else:\n",
    "    position_df.write.format(\"delta\").mode(\"overwrite\").save(position_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ac2d91-b485-414e-8d8f-af93335f1b60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(position_path)\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4382d53-5d19-4d45-96c2-05c84c70257b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### District dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d055777-7744-4e2c-9e1a-4dc903760cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "district_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/district/district.csv\")\n",
    "district_df.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://silver@sabankingkd.dfs.core.windows.net/district/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb905948-16c9-41ca-b6d3-c79f2e8858f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(\"abfss://silver@sabankingkd.dfs.core.windows.net/district/\")\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6dfd18ab-4922-49f5-bf2a-bea67f695881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loan Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aca88184-31f2-468f-855c-659e5c8808b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/loan/loan.csv\")\n",
    "status_df = loan_df.withColumn(\"status\", when(col(\"status\") == \"A\" , \"Active\").otherwise(\"Inactive\")).withColumn(\"enddate\", lit(\"9999-09-09\"))\n",
    "loan_final_df = status_df.select(\"loan_id\", \"account_id\", \"amount\", \"duration\", \"payments\", \"status\", col(\"fulldate\").cast(\"date\").alias(\"loandate\"),col(\"enddate\").cast(\"string\").alias(\"enddate\"),\"location\", \"purpose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2790b542-ac18-4314-b6fd-af0c6454781a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loan_final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f18db4-e6dd-47c0-8aff-bfa7c0287a66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Apply SCD type 2 logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a4a449c-d3ce-4d00-8865-15b8ab2b45a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 31"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "loan_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/loan/\"\n",
    "def path_exists(loan_path):\n",
    "    try:\n",
    "        dbutils.fs.ls(loan_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if not path_exists(loan_path):\n",
    "    loan_final_df.write.format(\"delta\").mode(\"overwrite\").save(loan_path)\n",
    "else:\n",
    "    loan_new_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/loan/loan_new.csv\")\n",
    "    loan_new_df = loan_new_df.select(col(\"loan_id\").alias(\"loan_id_new\"), col(\"account_id\").alias(\"account_id_new\"), col(\"amount\").alias(\"amount_new\"), col(\"duration\").alias(\"duration_new\"), col(\"payments\").alias(\"payments_new\"), col(\"status\").alias(\"status_new\"), col(\"loandate\").alias(\"loandate_new\"), col(\"enddate\").alias(\"enddate_new\"), col(\"location\").alias(\"location_new\"), col(\"purpose\").alias(\"purpose_new\"))\n",
    "\n",
    "    left_join_df = loan_final_df.join(loan_new_df, loan_final_df['loan_id'] == loan_new_df['loan_id_new'], \"left\")\n",
    "\n",
    "    filter_changed_and_active = left_join_df.filter((left_join_df.status_new == \"Active\") & (left_join_df.payments != left_join_df.payments_new))\n",
    "    filter_changed_and_active = filter_changed_and_active.select(col(\"loan_id_new\").alias(\"loan_id\"), col(\"account_id_new\").alias(\"account_id\"), col(\"amount_new\").alias(\"amount\"), col(\"duration_new\").alias(\"duration\"), col(\"payments_new\").alias(\"payments\"), col(\"status_new\").alias(\"status\"), col(\"loandate_new\").alias(\"loandate\"), col(\"enddate_new\").cast(\"date\").alias(\"enddate\"), col(\"location_new\").alias(\"location\"), col(\"purpose_new\").alias(\"purpose\"))\n",
    "\n",
    "    make_loan_inactive = filter_changed_and_active.withColumn(\"status\", lit(\"Inactive\"))\\\n",
    "                                              .withColumn(\"enddate\", (col(\"loandate\") - 1).cast(\"string\"))\n",
    "\n",
    "    # union_all_df = loan_final_df.union(make_loan_inactive)\n",
    "\n",
    "    make_loan_inactive.write.format(\"delta\").mode(\"append\").save(loan_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d10fec-2bad-4de3-a59f-c936e2c037d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# scd_check = union_all_df.filter(union_all_df.loan_id.isin([\"L00005657\",\"L00006699\"])).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bd762be-be94-4cb3-935c-da2646e6e47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(loan_path)\n",
    "# # display(df)\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad896eed-0948-4b0a-8c53-ebc6e340d27c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Order Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9152b946-4b2d-4811-abe2-9f6f4e7d4498",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Incremental load using merge statement\n",
    "from delta.tables import DeltaTable\n",
    "order_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/order/\"\n",
    "order_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/order/order.csv\")\n",
    "\n",
    "if not DeltaTable.isDeltaTable(spark, order_path):\n",
    "  order_df.write.format(\"delta\").save(order_path)\n",
    "else:\n",
    "    last_order_id = spark.read.format(\"delta\").load(order_path).select( max(col(\"order_id\"))).collect()[0][0]\n",
    "    incremental_order_df  = order_df.filter(col(\"order_id\") > last_order_id)\n",
    "    DeltaTable.forPath(spark, order_path).alias(\"target\").merge(\n",
    "        incremental_order_df.alias(\"source\"),\n",
    "        \"target.order_id = source.order_id\").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "# Increment this dataset using order_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca16fb4-a577-458e-8440-74baede3b1f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(order_path)\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7aa12ce-4388-48ad-bfea-a78badb3a9c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Transactions Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a908fb07-e51b-4878-b4bf-7eb52256bfb8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 32"
    }
   },
   "outputs": [],
   "source": [
    "#  use widgets to load the file by year\n",
    "transactions_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"abfss://broze@sabankingkd.dfs.core.windows.net/transactions/\")\n",
    "transactions_final_df = transactions_df.select(\"trans_id\", \"account_id\", \"type\", \"operation\", \"amount\", \"balance\", \"k_symbol\", \"bank\", \"account\", col(\"fulldate\").cast(\"date\").alias(\"transdate\"),col(\"fulldatewithtime\").alias(\"trans_datetime\")).withColumn(\"year\", year(col(\"transdate\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2027361-089d-4427-942f-e231bf11a3d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "transactions_path = \"abfss://silver@sabankingkd.dfs.core.windows.net/transactions/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6a6e1df-f604-4363-807c-1e3b9f43cfec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def path_exists(transactions_path):\n",
    "    try:\n",
    "        dbutils.fs.ls(transactions_path)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4697d38b-125d-4626-98d0-a616be7d985d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 35"
    }
   },
   "outputs": [],
   "source": [
    "# Incremental loading\n",
    "if path_exists(transactions_path):\n",
    "    silver_df = spark.read.format(\"delta\").load(transactions_path).select(\"trans_id\")\n",
    "    incremental_transactions_df = transactions_final_df.join(\n",
    "        silver_df,\n",
    "        on=\"trans_id\",\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "    incremental_transactions_df.write.format(\"delta\") \\\n",
    "    .partitionBy(\"year\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(transactions_path)\n",
    "else:\n",
    "    transactions_final_df.write.format(\"delta\").partitionBy(\"year\").mode(\"overwrite\").save(transactions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474f3824-41f5-422e-a051-7e191a9991a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").load(transactions_path + \"/year=2013\")\n",
    "# df_count = df.count()\n",
    "# print(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad04bbe6-8f3c-48a9-97a1-e7f689fe00b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.notebook.exit(\"Successfully loaded\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
